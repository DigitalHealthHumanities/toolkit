---
layout: sublesson
structurehead: CommandLine
group: databasics
nest: windows
title: "Synthesis"
abstract: "In this section you will learn about the history of the command line in computers, and why it matters for doing digital research."
lessonnumber: 15
lessonprint: 4
permalink: /lessons/databasics/commandline/4
previouslesson: n/a
split: back
nextlesson: n/a
splitmac: /lessons/databasics/commandline/3a3
splitpc: /lessons/databasics/commandline/3b4
---

Using the tools you have learned in this lesson, I want you to create a new file. I want you to search for terms related to meningeal tuberculosis, using “meningeal” as the search term—meningeal, meningitis, meninges. 

Remember: you do not have to search each of these three terms separately. There is a function we learned in this lesson that will help you search multiple words with a similar beginning or ending. 

Spoiler: Meningeal Tuberculosis Search (Windows} 

    findstr /i “mening*” *.txt > outputs\meningealsearch.txt 

What can we do with this text file?? We counted terms earlier in this lesson (see sections 3b.1 and [!!!mac version]), and that helped us find specific texts that focused on specific interests in the period. But now we are generating texts, which are themselves too long to gloss. 

What we can do with these files is use them for **textual analysis**. 

<p style="margin-left: 40px"><b>Important Term - Textual Analysis:</b> Textual analysis (or text analysis for short) refers to any method that examines large amounts of text using computational tools. Text analysis historically was used to count the use of specific words, and look at their context with other words. More contemporary text analysis uses large language models and machine learning to develop more complex groupings of interrelated words (topic modelling) or weight texts based on the positive or negative affect of words used (sentiment analysis).</p> 

There are more lessons on text analysis elsewhere in this toolkit ([!!!!links go here]), but wec an look at the documents we generated and see that they are covering very different parts of the corpus we examined. For this lesson, we will use Voyant: an open-source text analysis platform that is very well suited for teaching. 

Go to voyant-tools.org in a separate tab in your browser. 

Once there, click on the “upload” button and navigate to the text you generated. Once you upload it, you’ll see a dashboard with LOTS of different pieces of information. 

We will cover some of the various methods that Voyant enables elsewhere in this toolkit ([!!!Links go here]), but for now I want us to focus on one interface.  

In the upper right-hand corner of the dashboard there is a panel that shows the frequency of terms across the document. Voyant breaks these terms down when it processes the file. If you have multiple files, it will show every file in the collection in this view, or if you have one file, like in this example, it will partition that file evenly. It also generates the relative frequency based on the size of the chunk it generates. This view can help point to specific places in the file or collection of files where interests are unique. 

Look at the Voyant generated graphs. Here is the meningeal tuberculosis graph. What is going on with that spike in the use of the terms “died” and “day”? 

![]({{ site.baseurl}}/assets/img/CLVoy2.jpg)

By looking at this interface we may be to make some preliminary assumptions: maybe “died” and “day” are connected because the use meningeal is used in diagnosis, and may be mentioned in case studies and case histories. “Died” and “day” may be referring to moments when patients died, or days when they had notable symptoms. 

Let’s look quickly at the word cloud in the upper left-hand corner of the interface: 

![]({{ site.baseurl }}/assets/img/CLVoy6.jpg)

Word clouds are generated by counting every instance of every unique term in the file, and then scaling the size of each word based on its relative frequency to the others. We can see the five terms in the previous graph, but a bunch of other terms that are not quite as significant. 

There are a few things I want to point out. First, is that there’s some words from the generated file: “theamericanreviewoftuberc11_1925” and “txt”. These occurred because we did not clean the file before uploading it. 

<p style="margin-left: 40px"><b>Important Concept: Data Cleaning –</b> Often we have to make the files we are using in our digital research compatible with our platforms. We have to deal with any errant mistakes or issues with those data sources. Removing the unnecessary information in data files is known as data cleaning. </p>

Second, there are some interesting terms popping up: “moribund”, “tubercles”, “spinal”, “fluid”, “symptoms”. These could be used to do further searches, or could help determine something about the relationship of the word meningeal and this kind of symptomatic language. 

Importantly, the search we did looks different than if we uploaded the entire collection of texts to Voyant. 

![]({{ site.baseurl }}/assets/img/CLVoy7.jpg)

These are much more general because they describe the entire corpus. Searching and generating files from those searches can make more specific explorations of the broader collection of texts. 